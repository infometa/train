# audioCompare.py (ä¿®å¤ç‰ˆ V2)
"""
AudioCompare Expert V2 - è‡ªåŠ¨å¯¹é½ + é«˜æ¸…åˆ†æç‰ˆ

ä¿®å¤æ—¥å¿—ï¼š
1. [ä¿®å¤] ç§»é™¤äº† st.audio() ä¸­ä¸æ”¯æŒçš„ label å‚æ•°ï¼Œæ”¹ä¸º st.markdown() æ˜¾ç¤ºã€‚
2. [åŠŸèƒ½] åŒ…å«è‡ªåŠ¨å¯¹é½ã€é«˜æ¸…é¢‘è°±ã€PSDã€LSD/PESQ/STOI è®¡ç®—ã€‚

ä¾èµ–: pip install streamlit matplotlib numpy scipy librosa soundfile torch pesq pystoi
"""

import streamlit as st
import numpy as np
import soundfile as sf
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import librosa
import librosa.display
import io
import os
import urllib.request
from scipy import signal, stats
from scipy.signal import welch

# å°è¯•å¯¼å…¥å¬æ„ŸæŒ‡æ ‡åº“
try:
    from pesq import pesq
    from pystoi import stoi
    METRICS_AVAILABLE = True
except ImportError:
    METRICS_AVAILABLE = False

# ================= 1. å­—ä½“é…ç½® (é˜²ä¹±ç ) =================
def configure_font():
    font_name = "SimHei.ttf"
    font_url = "https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf"
    
    if not os.path.exists(font_name):
        try:
            opener = urllib.request.build_opener()
            opener.addheaders = [('User-agent', 'Mozilla/5.0')]
            urllib.request.install_opener(opener)
            urllib.request.urlretrieve(font_url, font_name)
        except Exception:
            pass

    if os.path.exists(font_name):
        try:
            fm.fontManager.addfont(font_name)
            plt.rcParams['font.sans-serif'] = ['SimHei']
            plt.rcParams['axes.unicode_minus'] = False
            return True
        except: pass
    
    # å›é€€
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False
    return False

HAS_FONT = configure_font()

# ================= 2. æ ¸å¿ƒç®—æ³•ï¼šè‡ªåŠ¨å¯¹é½ =================

def align_signals(ref, deg, sr, max_shift_ms=200):
    """
    è‡ªåŠ¨å¯¹é½ä¸¤ä¸ªä¿¡å· (Cross-Correlation)
    """
    # 1. ç²—ç•¥å¯¹é½ä¸éœ€è¦å…¨é•¿ï¼Œå–å‰ 30ç§’ è¶³å¤Ÿ
    max_len = min(len(ref), len(deg), sr * 30)
    ref_slice = ref[:max_len]
    deg_slice = deg[:max_len]
    
    # 2. å½’ä¸€åŒ–å»ç›´æµ
    ref_slice = ref_slice - np.mean(ref_slice)
    deg_slice = deg_slice - np.mean(deg_slice)
    
    # 3. è®¡ç®—äº’ç›¸å…³
    corr = signal.correlate(ref_slice, deg_slice, mode='full', method='fft')
    lags = signal.correlation_lags(len(ref_slice), len(deg_slice), mode='full')
    
    # æ‰¾åˆ°å³°å€¼
    best_idx = np.argmax(corr)
    lag = lags[best_idx]
    
    # 4. åº”ç”¨ä½ç§»
    if lag > 0:
        deg_aligned = deg[lag:]
        ref_aligned = ref
    elif lag < 0:
        deg_aligned = deg[abs(lag):]
        ref_aligned = ref
    else:
        deg_aligned = deg
        ref_aligned = ref
        
    # 5. å†æ¬¡å¼ºåˆ¶ç­‰é•¿æˆªæ–­
    min_len = min(len(ref_aligned), len(deg_aligned))
    return ref_aligned[:min_len], deg_aligned[:min_len], lag

def load_audio(file, target_sr=48000):
    audio, sr = sf.read(file)
    if audio.ndim > 1: audio = audio.mean(axis=1)
    if sr != target_sr:
        audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)
        sr = target_sr
    return audio.astype(np.float32), sr

# ================= 3. æŒ‡æ ‡è®¡ç®— =================

def compute_metrics(ref, deg, sr):
    metrics = {}
    
    # SI-SNR
    eps = 1e-8
    ref_en = np.sum(ref**2) + eps
    scale = np.dot(ref, deg) / ref_en
    proj = scale * ref
    noise = deg - proj
    metrics['SI-SNR'] = 10 * np.log10(np.sum(proj**2) / (np.sum(noise**2) + eps))
    
    # LSD (åˆ†é¢‘æ®µ)
    S_ref = np.abs(librosa.stft(ref))**2
    S_deg = np.abs(librosa.stft(deg))**2
    log_diff = (10 * np.log10(S_ref+eps) - 10 * np.log10(S_deg+eps))**2
    
    freqs = librosa.fft_frequencies(sr=sr)
    mask_high = freqs > 10000
    metrics['LSD High'] = np.mean(np.sqrt(np.mean(log_diff[mask_high], axis=0)))
    metrics['LSD All'] = np.mean(np.sqrt(np.mean(log_diff, axis=0)))
    
    # L1
    metrics['L1'] = np.mean(np.abs(ref - deg))

    # PESQ/STOI
    if METRICS_AVAILABLE:
        try:
            r16 = librosa.resample(ref, orig_sr=sr, target_sr=16000)
            d16 = librosa.resample(deg, orig_sr=sr, target_sr=16000)
            metrics['PESQ'] = pesq(16000, r16, d16, 'wb')
            metrics['STOI'] = stoi(r16, d16, 16000)
        except: pass
        
    return metrics

# ================= 4. ç•Œé¢é€»è¾‘ =================

st.set_page_config(layout="wide", page_title="AudioCompare Expert V2")
st.title("ğŸ›ï¸ éŸ³è‰²ä¿®å¤ä¸“å®¶å° V2 (Auto-Align + Hi-Res)")

if not METRICS_AVAILABLE:
    st.warning("æç¤º: æœªå®‰è£… pesq/pystoiï¼Œå¬æ„ŸæŒ‡æ ‡å°†éšè—ã€‚")

# ä¾§è¾¹æ é…ç½®
st.sidebar.header("ğŸ”§ è®¾ç½®")
enable_align = st.sidebar.checkbox("å¯ç”¨è‡ªåŠ¨å¯¹é½ (Auto-Align)", value=True, help="è‡ªåŠ¨è®¡ç®—å»¶è¿Ÿå¹¶å¯¹é½éŸ³é¢‘ï¼Œè®¡ç®— Diff å’Œ SNR å¿…é¡»å¼€å¯ã€‚")
spectrogram_clim = st.sidebar.slider("é¢‘è°±å›¾åŠ¨æ€èŒƒå›´ (dB)", min_value=40, max_value=120, value=80)

col1, col2 = st.columns([1, 2])
with col1:
    ref_file = st.file_uploader("1. å‚è€ƒéŸ³é¢‘ (Ref/Clean)", type=["wav", "flac"])
    comp_files = st.file_uploader("2. å¾…æµ‹éŸ³é¢‘ (Models)", type=["wav", "flac"], accept_multiple_files=True)

if ref_file and comp_files:
    # 1. åŠ è½½ Ref
    ref_raw, sr = load_audio(ref_file)
    audio_store = {"Ref": ref_raw}
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### æ’­æ”¾ (å·²å¯¹é½)")
    st.sidebar.markdown("**Ref (Original)**") # [ä¿®å¤] æ‰‹åŠ¨æ˜¾ç¤ºæ ‡ç­¾
    st.sidebar.audio(ref_file) # [ä¿®å¤] ç§»é™¤ label å‚æ•°

    # 2. å¤„ç†æ‰€æœ‰å¾…æµ‹æ–‡ä»¶
    results = []
    pbar = st.progress(0)
    
    for i, f in enumerate(comp_files):
        deg_raw, _ = load_audio(f, target_sr=sr)
        
        # å¯¹é½
        if enable_align:
            ref_aligned, deg_aligned, lag = align_signals(ref_raw, deg_raw, sr)
            status_text = f"âœ… Shift: {lag}"
        else:
            min_l = min(len(ref_raw), len(deg_raw))
            ref_aligned = ref_raw[:min_l]
            deg_aligned = deg_raw[:min_l]
            status_text = "âš ï¸ Unaligned"
            
        audio_store[f.name] = deg_aligned
        
        # è®¡ç®—
        m = compute_metrics(ref_aligned, deg_aligned, sr)
        
        row = {
            "Model": f.name,
            "Align": status_text,
            "SI-SNR": m['SI-SNR'],
            "LSD High": m['LSD High'],
            "PESQ": m.get('PESQ', 0),
            "STOI": m.get('STOI', 0),
            "L1": m['L1']
        }
        results.append(row)
        
        # [ä¿®å¤] ä¾§è¾¹æ æ’­æ”¾åˆ—è¡¨
        st.sidebar.markdown(f"**{f.name}**") # æ‰‹åŠ¨æ˜¾ç¤ºæ ‡ç­¾
        with io.BytesIO() as buf:
            sf.write(buf, deg_aligned, sr, format='WAV')
            st.sidebar.audio(buf) # ç§»é™¤ label å‚æ•°
            
        pbar.progress((i + 1) / len(comp_files))
    
    pbar.empty()

    # === å±•ç¤ºæ•°æ® ===
    st.subheader("1. æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯”")
    st.dataframe(
        results,
        column_config={
            "SI-SNR": st.column_config.NumberColumn("SI-SNR (dB) â†‘", format="%.2f"),
            "LSD High": st.column_config.NumberColumn("é«˜é¢‘å¤±çœŸ (LSD) â†“", format="%.2f"),
            "PESQ": st.column_config.NumberColumn("PESQ (å¬æ„Ÿ) â†‘", format="%.2f"),
            "L1": st.column_config.NumberColumn("L1 Error â†“", format="%.5f"),
        },
        use_container_width=True
    )
    
    # === å±•ç¤ºé«˜æ¸…å›¾è¡¨ ===
    st.subheader("2. é¢‘è°±ä¸ç»†èŠ‚ (High-Res)")
    
    num_files = len(audio_store)
    fig = plt.figure(figsize=(14, 4 * num_files), dpi=150)
    gs = fig.add_gridspec(num_files, 2, width_ratios=[3, 1])

    for idx, (name, y) in enumerate(audio_store.items()):
        # å·¦å›¾ï¼šSpectrogram
        ax_spec = fig.add_subplot(gs[idx, 0])
        D = librosa.amplitude_to_db(np.abs(librosa.stft(y, n_fft=2048, hop_length=256)), ref=np.max)
        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='linear', 
                               ax=ax_spec, cmap='magma', vmin=-spectrogram_clim, vmax=0)
        ax_spec.set_title(f"{name} - Spectrogram", fontsize=10)
        ax_spec.set_ylim(0, 24000)
        ax_spec.set_xlabel("")
        if idx == num_files - 1: ax_spec.set_xlabel("Time (s)")

        # å³å›¾ï¼šPSD (é«˜é¢‘ç‰¹å†™)
        ax_psd = fig.add_subplot(gs[idx, 1])
        f_p, Pxx = welch(y, sr, nperseg=1024)
        Pxx_db = 10 * np.log10(Pxx + 1e-12)
        
        if name != "Ref":
            f_ref, P_ref = welch(audio_store["Ref"], sr, nperseg=1024)
            ax_psd.plot(f_ref, 10*np.log10(P_ref+1e-12), color='grey', alpha=0.3, label='Ref')
            
        ax_psd.plot(f_p, Pxx_db, color='tab:orange', linewidth=1.5, label=name)
        ax_psd.set_title("PSD (High Freq)", fontsize=10)
        ax_psd.set_xlim(8000, 24000)
        ax_psd.set_ylim(-100, -20)
        ax_psd.grid(True, alpha=0.3)
        ax_psd.legend(fontsize=8)

    plt.tight_layout()
    st.pyplot(fig)
    
    # === å·®åˆ†è¯•å¬ ===
    st.subheader("3. å·®åˆ†æ£€è§† (Residual Check)")
    st.markdown("æ’­æ”¾ `Clean - Restored`ã€‚**å¬åˆ°äº†æ¸…æ™°äººå£° = ä¿®å¤å¤±è´¥ï¼ˆä¸¢å¤±ä¿¡æ¯ï¼‰ã€‚**")
    
    diff_cols = st.columns(len(comp_files))
    ref_wav = audio_store["Ref"]
    
    for i, f in enumerate(comp_files):
        name = f.name
        deg_wav = audio_store[name]
        l = min(len(ref_wav), len(deg_wav))
        diff = ref_wav[:l] - deg_wav[:l]
        
        with diff_cols[i]:
            st.markdown(f"**Diff: {name}**")
            with io.BytesIO() as buf:
                sf.write(buf, diff * 2.0, sr, format='WAV')
                st.audio(buf)

else:
    st.info("ğŸ‘‹ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ æ–‡ä»¶ã€‚æ¨èå…ˆå‹¾é€‰ 'Auto-Align'ã€‚")